{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Classification Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "sys.path.append(\"../gnnexp\")\n",
    "from models import GNN_Custom_Mutag, GNN_Custom_NCI1, GNN_Custom_IsCyclic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"NCI1\" # OPTIONS: Mutagenicity, NCI1, IsCyclic\n",
    "EVAL = \"train\" # OPTIONS: eval, train\n",
    "#todo: MUTAG dataset is different from other baselines.\n",
    "\n",
    "if DATASET == 'NCI1':\n",
    "    EXPLANATION_FOLDER = \"nci1_dc_top20\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = dict()\n",
    "PATH = f\"../explanation/{EXPLANATION_FOLDER}\"\n",
    "for filename in os.listdir(PATH):\n",
    "    if 'label' not in filename:\n",
    "        continue\n",
    "    graph_idx = ''.join(filter(lambda i: i.isdigit(), filename))\n",
    "    explanations[int(graph_idx)] = pd.read_csv(f\"{PATH}/{filename}\", header=None).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "536"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(f\"../data/{DATASET}/eval_as_{EVAL}.pt\")\n",
    "cg_dict = ckpt[\"cg\"] # get computation graph\n",
    "input_dim = cg_dict[\"feat\"].shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNN_Custom_Graph(\n",
       "  (conv1): GraphConvolution (37 -> 128)\n",
       "  (conv2): GraphConvolution (128 -> 128)\n",
       "  (conv3): GraphConvolution (128 -> 128)\n",
       "  (dense1): Linear(in_features=128, out_features=16, bias=True)\n",
       "  (dense2): Linear(in_features=16, out_features=8, bias=True)\n",
       "  (dense3): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GNN_Custom_Graph(in_features=input_dim, h_features=128)\n",
    "model.load_state_dict(ckpt[\"model_state\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list()\n",
    "labels = list()\n",
    "for graph_idx in cg_dict['test_idx']:\n",
    "    feat = cg_dict[\"feat\"][graph_idx, :].float().unsqueeze(0)\n",
    "    adj = cg_dict[\"adj\"][graph_idx].float().unsqueeze(0) # - explanations[graph_idx]\n",
    "    label = cg_dict[\"label\"][graph_idx].float().unsqueeze(0)\n",
    "    proba = model(feat, adj)\n",
    "    predictions.append(proba.round())\n",
    "    labels.append(label)\n",
    "predictions = torch.Tensor(predictions)\n",
    "labels = torch.Tensor(labels)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(100.)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * (predictions == labels).sum() / len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fidelity & Explanation size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_indices = dict() # They are from the Upper Triangular part only.\n",
    "top_k = 20\n",
    "for graph_id, graph in explanations.items():\n",
    "    # triu: Upper Triangular\n",
    "    # abs: These are indices of the flattended version, not of the 2D version.\n",
    "    triu_abs_top_indices = (-np.triu(graph).flatten()).argsort()[:top_k]\n",
    "    index_rows = triu_abs_top_indices // graph.shape[0]\n",
    "    index_cols = triu_abs_top_indices % graph.shape[0]\n",
    "    triu_top_k_indices = [(r,c) for r,c in zip(index_rows, index_cols)]\n",
    "    top_indices[graph_id] = triu_top_k_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_size_list = list()\n",
    "cf_found_count = 0\n",
    "\n",
    "for graph_id, graph in explanations.items():\n",
    "    feat = cg_dict[\"feat\"][graph_id, :].float().unsqueeze(0)\n",
    "    adj = cg_dict[\"adj\"][graph_id].float().unsqueeze(0)\n",
    "    label = cg_dict[\"label\"][graph_id].long().unsqueeze(0)\n",
    "    \n",
    "    # get original prediction\n",
    "    original_prediction = model(feat, adj).round()\n",
    "\n",
    "    # set size_count to 0\n",
    "    # make a copy of the original adjacency.\n",
    "    size_count = 0\n",
    "    new_adj = adj.clone()\n",
    "\n",
    "    # work on correctly predicted label 1 nodes only.\n",
    "    if label == 1 and original_prediction == 1:\n",
    "        go = True\n",
    "    else:\n",
    "        go = False\n",
    "    if not go:\n",
    "        continue\n",
    "\n",
    "    for index in top_indices[graph_id]:\n",
    "        r1, c1 = index\n",
    "        r2, c2 = c1, r1 # for the lower triangular part.\n",
    "\n",
    "        # remove the edges\n",
    "        new_adj[0][r1, c1] = 0.0\n",
    "        new_adj[0][r2, c2] = 0.0\n",
    "\n",
    "        # make the prediction\n",
    "        new_prediction = model(feat, new_adj).round()\n",
    "\n",
    "\n",
    "        # increase size_count by 1.\n",
    "        size_count += 1\n",
    "\n",
    "        # if the label flipped: stop\n",
    "        if original_prediction != new_prediction:\n",
    "            cf_found_count += 1\n",
    "            explanation_size_list.append(size_count)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity: 0.20\n",
      "Explanation size: mean=2.53, std=2.44\n"
     ]
    }
   ],
   "source": [
    "fidelity = 1 - cf_found_count/len(explanations)\n",
    "exp_size_mean, exp_size_std = np.mean(explanation_size_list), np.std(explanation_size_list)\n",
    "\n",
    "print(f\"Fidelity: {fidelity:.2f}\")\n",
    "print(f\"Explanation size: mean={exp_size_mean:.2f}, std={exp_size_std:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_108 = pd.read_csv(\n",
    "    \"../explanation/iscyclic_top20/graph_idx_108_label.csv\",\n",
    "    header=None\n",
    ").to_numpy()\n",
    "\n",
    "pred_108 = pd.read_csv(\n",
    "    \"../explanation/iscyclic_top20/graph_idx_108_pred.csv\",\n",
    "    header=None\n",
    ").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.653016686439514"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_108.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.75364321, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_108[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103.88614672608674"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_108.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.024986  , 0.024986  , 0.024986  , 0.024986  , 0.024986  ,\n",
       "       0.024986  , 0.024986  , 0.024986  , 0.024986  , 0.024986  ,\n",
       "       0.024986  , 0.024986  , 0.024986  , 0.024986  , 0.024986  ,\n",
       "       0.024986  , 0.024986  , 0.024986  , 0.024986  , 0.024986  ,\n",
       "       0.024986  , 0.024986  , 0.024986  , 0.024986  , 0.00050399,\n",
       "       0.00050399, 0.00050399, 0.00050399, 0.00050399, 0.00050399,\n",
       "       0.00050399, 0.00050399, 0.00050399, 0.00050399, 0.00050399,\n",
       "       0.00050399, 0.00050399, 0.00050399, 0.00050399, 0.00050399,\n",
       "       0.00050399, 0.00050399, 0.00050399, 0.00050399, 0.00050399,\n",
       "       0.00050399, 0.00050399, 0.00050399, 0.00050399, 0.00050399,\n",
       "       0.00050399, 0.00050399, 0.00050399, 0.00050399, 0.00050399,\n",
       "       0.00050399, 0.00050399, 0.00050399, 0.00050399, 0.00050399,\n",
       "       0.00050399, 0.00050399, 0.00050399, 0.00050399, 0.00050399,\n",
       "       0.00050399, 0.00050399, 0.00050399, 0.00050399, 0.00050399,\n",
       "       0.00050399, 0.00050399, 0.00050399, 0.00050399, 0.00050399,\n",
       "       0.00050399, 0.00050399, 0.00050399, 0.00050399, 0.00050399,\n",
       "       0.00050399, 0.00050399, 0.00050399, 0.00050399, 0.00050399,\n",
       "       0.00050399, 0.00050399, 0.00050399, 0.00050399, 0.00050399,\n",
       "       0.00050399, 0.00050399, 0.00050399, 0.00050399, 0.00050399,\n",
       "       0.00050399, 0.00050399, 0.00050399, 0.00050399, 0.00050399,\n",
       "       0.00050399, 0.00050399, 0.00050399, 0.00050399, 0.00050399,\n",
       "       0.00050399])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_108[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('gem')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6cbbe528126ce4ff858253ebeac4791d5498c577849f0c2b8ed17d9a06b9b755"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
