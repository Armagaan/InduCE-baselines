{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "sys.path.append(\"../gnnexp\")\n",
    "from models import GCNSynthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ===== CONSTANTS =====\n",
    "DATASET = \"syn1\"\n",
    "EVAL = \"eval\"\n",
    "OUTPUTS = \"../output/syn1/1658400488/\"\n",
    "\n",
    "if  DATASET not in ['syn1', 'syn4', 'syn5']:\n",
    "    print(\"INVALID DATASET!\")\n",
    "elif EVAL not in ['eval', 'train']:\n",
    "    print(\"INVALID EVALMODE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'explanation/syn1_top6'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/shade/code/github/Counterfactual-Baselines/Gem/tests/baseilnes.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/shade/code/github/Counterfactual-Baselines/Gem/tests/baseilnes.ipynb#ch0000004vscode-remote?line=8'>9</a>\u001b[0m explanations \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/shade/code/github/Counterfactual-Baselines/Gem/tests/baseilnes.ipynb#ch0000004vscode-remote?line=9'>10</a>\u001b[0m PATH \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexplanation/\u001b[39m\u001b[39m{\u001b[39;00mDATASET\u001b[39m}\u001b[39;00m\u001b[39m_top6\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/shade/code/github/Counterfactual-Baselines/Gem/tests/baseilnes.ipynb#ch0000004vscode-remote?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(PATH):\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/shade/code/github/Counterfactual-Baselines/Gem/tests/baseilnes.ipynb#ch0000004vscode-remote?line=11'>12</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mpred\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m filename:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/shade/code/github/Counterfactual-Baselines/Gem/tests/baseilnes.ipynb#ch0000004vscode-remote?line=12'>13</a>\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'explanation/syn1_top6'"
     ]
    }
   ],
   "source": [
    "# The extracted subadjacency matrices.\n",
    "with open(f\"{OUTPUTS}/original_sub_data.pkl\", \"rb\") as file:\n",
    "    sub_data = pickle.load(file)\n",
    "sub_labels = dict()\n",
    "for node in sub_data:\n",
    "    new_idx = sub_data[node]['node_idx_new']\n",
    "    sub_labels[node] = int(sub_data[node]['sub_label'][new_idx])\n",
    "\n",
    "explanations = dict()\n",
    "PATH = f\"explanation/{DATASET}_top6\"\n",
    "for filename in os.listdir(PATH):\n",
    "    if 'pred' not in filename:\n",
    "        continue\n",
    "    node_idx = ''.join(filter(lambda i: i.isdigit(), filename))\n",
    "    explanations[int(node_idx)] = pd.read_csv(f\"{PATH}/{filename}\", header=None).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(f\"data/{DATASET}/eval_as_{EVAL}.pt\")\n",
    "cg_dict = ckpt[\"cg\"]\n",
    "input_dim = cg_dict[\"feat\"].shape[2] \n",
    "num_classes = cg_dict[\"pred\"].shape[2]\n",
    "feat = torch.from_numpy(cg_dict[\"feat\"]).float()\n",
    "adj = torch.from_numpy(cg_dict[\"adj\"]).float()\n",
    "label = torch.from_numpy(cg_dict[\"label\"]).long()\n",
    "with open(f\"tests/prog_args_{DATASET}.pkl\", \"rb\") as file:\n",
    "    prog_args = pickle.load(file)\n",
    "\n",
    "model = GCNSynthetic(\n",
    "    nfeat=input_dim,\n",
    "    nhid=prog_args.hidden_dim,\n",
    "    nout=prog_args.output_dim,\n",
    "    nclass=num_classes,\n",
    "    dropout=0.0,\n",
    ")\n",
    "model.load_state_dict(ckpt[\"model_state\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dict()\n",
    "for node in explanations:\n",
    "    sub_adj = sub_data[node]['org_adj'] - torch.Tensor(explanations[node]).unsqueeze(0)\n",
    "    new_idx = sub_data[node]['node_idx_new']\n",
    "    pred_proba = model(\n",
    "        sub_data[node]['sub_feat'],\n",
    "        sub_adj\n",
    "    ).squeeze(0)\n",
    "    predictions[node] = int(torch.argmax(pred_proba[new_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassifications = 0\n",
    "for node in predictions:\n",
    "    if predictions[node] != sub_labels[node]:\n",
    "        misclassifications += 1\n",
    "fidelity = 1 - misclassifications/len(predictions)\n",
    "print(\"\\n===============\")\n",
    "print(f\"Fidelity: {fidelity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-label Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_label_mismatches = defaultdict(int)\n",
    "for node in predictions:\n",
    "    label = sub_labels[node]\n",
    "    if predictions[node] != label:\n",
    "        per_label_mismatches[int(label)] += 1\n",
    "labels, label_counts = torch.Tensor(list(sub_labels.values())).unique(return_counts=True)\n",
    "nodes_per_label = {\n",
    "    int(key):int(val) for key, val in zip(labels, label_counts)\n",
    "}\n",
    "print(\"\\n===============\")\n",
    "print(\"Per label fidelity:\")\n",
    "for label in per_label_mismatches:\n",
    "    print(f\"Label-{label}\", end=\": \")\n",
    "    print(f\"{1 - per_label_mismatches[label]/nodes_per_label[label]:.2f}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('gem')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6cbbe528126ce4ff858253ebeac4791d5498c577849f0c2b8ed17d9a06b9b755"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
