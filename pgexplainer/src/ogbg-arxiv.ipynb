{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OGBG Arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from math import ceil\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "from torch.nn.functional import dropout, relu\n",
    "from torch_geometric.explain import Explainer\n",
    "from torch_geometric.explain.algorithm import PGExplainer\n",
    "from torch_geometric.explain.config import ModelConfig\n",
    "from torch_geometric.explain.metric import fidelity\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PygNodePropPredDataset(name=\"ogbn-arxiv\", root=\"../data/\")\n",
    "graph = dataset[0] # pyg graph object\n",
    "features = graph.x\n",
    "edge_index = graph.edge_index\n",
    "labels = graph.y.flatten()\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = dataset.get_idx_split()\n",
    "idx_train_sampled = list()\n",
    "for i in range(40):\n",
    "    idx = (graph.y[split_idx['train']] == i).nonzero(as_tuple=False)\n",
    "    idx_sub = np.random.choice(idx[:,0].numpy(), size=10, replace=False)\n",
    "    idx_train_sampled.extend(idx_sub)\n",
    "\n",
    "idx_train_full = split_idx['train']\n",
    "idx_train = torch.tensor(idx_train_sampled, dtype=torch.long)\n",
    "idx_val = split_idx['valid']\n",
    "idx_test_full = split_idx['test']\n",
    "\n",
    "with open(\"../data/eval-sets/ogbg-arxiv.pickle\", \"rb\") as file:\n",
    "    eval_indices = pickle.load(file)\n",
    "eval_indices = sorted([i.item() for i in eval_indices])\n",
    "idx_test = split_idx['test'][eval_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(idx_train_full), len(idx_train_sampled), len(idx_val), len(idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[idx_train].unique(return_counts=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels[idx_train].unique(return_counts=True)[1] / labels[idx_train].unique(return_counts=True)[1].sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels, cached=False))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for __ in range(num_layers - 2):\n",
    "            self.convs.append(\n",
    "                GCNConv(hidden_channels, hidden_channels, cached=False))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.convs.append(GCNConv(hidden_channels, out_channels, cached=False))\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "        return\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, adj_t)\n",
    "            x = self.bns[i](x)\n",
    "            x = relu(x)\n",
    "            x = dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x.log_softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN = 256\n",
    "LAYERS = 3\n",
    "DROPOUT = 0.5\n",
    "LAYERS = 3\n",
    "\n",
    "model = GCN(\n",
    "    in_channels=128,\n",
    "    hidden_channels=HIDDEN,\n",
    "    out_channels=40,\n",
    "    num_layers=LAYERS,\n",
    "    dropout=DROPOUT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f\"../models/gcn_3layer_ogbg-arxiv.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(indices):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(graph.x, graph.edge_index)\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "    return (pred[indices] == graph.y.flatten()[indices]).sum().item() / len(pred[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Acc train (full): {test(idx_train_full):.4f}\")\n",
    "print(f\"Acc train: {test(idx_train):.4f}\")\n",
    "print(f\"Acc val: {test(idx_val):.4f}\")\n",
    "print(f\"Acc test (full): {test(idx_test_full):.4f}\")\n",
    "print(f\"Acc test (eval): {test(idx_test):.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "LR = 0.003\n",
    "TOP_K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#! For testing\n",
    "idx_train = idx_train[:2]\n",
    "idx_test = idx_test[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=PGExplainer(epochs=EPOCHS, lr=LR),\n",
    "    explanation_type=\"phenomenon\",\n",
    "    edge_mask_type=\"object\",\n",
    "    model_config=ModelConfig(\n",
    "        mode=\"multiclass_classification\",\n",
    "        task_level=\"node\",\n",
    "        return_type=\"log_probs\"\n",
    "    ),\n",
    "    threshold_config=dict(threshold_type='topk', value=TOP_K),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    for index in idx_train:\n",
    "        loss = explainer.algorithm.train(\n",
    "            epoch=epoch,\n",
    "            model=model,\n",
    "            x=graph.x,\n",
    "            edge_index=graph.edge_index,\n",
    "            target=graph.y.flatten(),\n",
    "            index=index.item()\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 nodes take 1 minute for 10 epochs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "start = perf_counter()\n",
    "for index in idx_test:\n",
    "    explanation = explainer(graph.x, graph.edge_index, target=graph.y.flatten(), index=index.item())\n",
    "end = perf_counter()\n",
    "print(\"Time elapsed:\", round(end - start, 2), \"seconds\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 second per explanation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_fidelity(indices):\n",
    "    fidelities = list()\n",
    "    for index in indices:\n",
    "        explanation = explainer(features, edge_index, target=labels, index=index.item())\n",
    "        fidelities.append(fidelity(explainer, explanation)[0])\n",
    "    fidelities = torch.tensor(fidelities, dtype=float)\n",
    "    return fidelities.mean(), fidelities.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fidelity_mean_train, fidelity_std_train = cal_fidelity(idx_train)\n",
    "fidelity_mean_test, fidelity_std_test = cal_fidelity(idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average training fidelity: {1 - fidelity_mean_train:.4f}, std={fidelity_std_train:.4f}\")\n",
    "print(f\"Average test fidelity: {1 - fidelity_mean_test:.4f}, std={fidelity_std_test:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average explanaiton size: {TOP_K}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_sparsity(indices, directed:bool = False):\n",
    "    sparsity_t = list()\n",
    "    # extract the subgraph\n",
    "    for node_index in indices:\n",
    "        __, __, __, edge_mask = k_hop_subgraph(\n",
    "            node_idx=node_index.item(),\n",
    "            num_hops=PGExplainer._num_hops(model),\n",
    "            edge_index=edge_index,\n",
    "            num_nodes=features.size(0),\n",
    "            flow=PGExplainer._flow(model),\n",
    "            directed=directed,\n",
    "        )\n",
    "        # find the number of edges in the subgraph.\n",
    "        num_edges = edge_mask.nonzero().size(0)\n",
    "        # account for undirected edges.\n",
    "        if not directed:\n",
    "            num_edges //= 2\n",
    "        if TOP_K > num_edges:\n",
    "            continue\n",
    "        try:\n",
    "            sparsity = 1 - (TOP_K / num_edges)\n",
    "        except ZeroDivisionError:\n",
    "            continue\n",
    "        sparsity_t.append(sparsity)\n",
    "    sparsity_t = torch.tensor(sparsity_t, dtype=float)\n",
    "    return sparsity_t.mean(), sparsity_t.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_mean_train, sparsity_std_train = cal_sparsity(idx_train, True)\n",
    "sparsity_mean_test, sparsity_std_test = cal_sparsity(idx_test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average train sparsity: {sparsity_mean_train:.4f}, std={sparsity_std_train:.4f}\")\n",
    "print(f\"Average test sparsity: {sparsity_mean_test:.4f}, std={sparsity_std_test:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg-2.3.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
