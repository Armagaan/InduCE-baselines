{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyG to CFGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fed206685f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from math import ceil\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "from torch.nn.functional import dropout, relu\n",
    "from torch_geometric.explain import Explainer\n",
    "from torch_geometric.explain.algorithm import PGExplainer\n",
    "from torch_geometric.explain.config import ModelConfig\n",
    "from torch_geometric.explain.metric import fidelity\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import k_hop_subgraph, to_dense_adj\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(num_nodes=169343, edge_index=[2, 1166243], x=[169343, 128], node_year=[169343, 1], y=[169343, 1])\n"
     ]
    }
   ],
   "source": [
    "dataset = PygNodePropPredDataset(name=\"ogbn-arxiv\", root=\"../data/\")\n",
    "graph = dataset[0] # pyg graph object\n",
    "features = graph.x\n",
    "edge_index = graph.edge_index\n",
    "labels = graph.y.flatten()\n",
    "print(graph)\n",
    "split_idx = dataset.get_idx_split()\n",
    "idx_train_sampled = list()\n",
    "for i in range(40):\n",
    "    idx = (graph.y[split_idx['train']] == i).nonzero(as_tuple=False)\n",
    "    idx_sub = np.random.choice(idx[:,0].numpy(), size=10, replace=False)\n",
    "    idx_train_sampled.extend(idx_sub)\n",
    "\n",
    "idx_train_full = split_idx['train']\n",
    "idx_train = torch.tensor(idx_train_sampled, dtype=torch.long)\n",
    "idx_val = split_idx['valid']\n",
    "idx_test_full = split_idx['test']\n",
    "\n",
    "with open(\"../data/eval-sets/ogbg-arxiv.pickle\", \"rb\") as file:\n",
    "    eval_indices = pickle.load(file)\n",
    "eval_indices = sorted([i.item() for i in eval_indices])\n",
    "idx_test = split_idx['test'][eval_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adj <class 'numpy.ndarray'> (1, 397, 397)\n",
      "feat <class 'numpy.ndarray'> (1, 397, 745)\n",
      "labels <class 'numpy.ndarray'> (1, 397)\n",
      "train_idx <class 'list'> 317\n",
      "test_idx <class 'list'> 80\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/gnn_explainer/small_amazon.pickle\", \"rb\") as file:\n",
    "    sa = pickle.load(file)\n",
    "for key, val in sa.items():\n",
    "    try:\n",
    "        print(key, type(val), val.shape)\n",
    "    except:\n",
    "        print(key, type(val), len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgnn = dict()\n",
    "# cfgnn[\"adj\"] = (graph.edge_index, torch.ones(size=(graph.edge_index.size(1),)))\n",
    "cfgnn[\"adj\"] = to_dense_adj(graph.edge_index).numpy()\n",
    "cfgnn[\"feat\"] = features.unsqueeze(0).numpy()\n",
    "cfgnn[\"labels\"] = labels.unsqueeze(0).numpy()\n",
    "cfgnn[\"train_idx\"] = idx_train.tolist()\n",
    "cfgnn[\"test_idx\"] = idx_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del graph, features, labels, idx_train, idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adj <class 'numpy.ndarray'> (1, 169343, 169343)\n",
      "feat <class 'numpy.ndarray'> (1, 169343, 128)\n",
      "labels <class 'numpy.ndarray'> (1, 169343)\n",
      "train_idx <class 'list'> 400\n",
      "test_idx <class 'list'> 1000\n"
     ]
    }
   ],
   "source": [
    "for key, val in cfgnn.items():\n",
    "    try:\n",
    "        print(key, type(val), val.shape)\n",
    "    except:\n",
    "        print(key, type(val), len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with open(\"../data/gnn_explainer/ogbg-arxiv.pickle\", \"wb\") as file:\n",
    "    pickle.dump(cfgnn, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg-2.3.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
