{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.utils import \\\n",
    "    k_hop_subgraph,\\\n",
    "    dense_to_sparse,\\\n",
    "    to_dense_adj,\\\n",
    "    subgraph\n",
    "\n",
    "sys.path.append(\"../src/utils\")\n",
    "from utils import get_neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the datset\n",
    "DATASET=\"treecycles\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == \"bashapes\":\n",
    "    path_log = \"../outputs/bashapes/1655241109/log.txt\"\n",
    "    path_cfs = \"../results/syn1/random/syn1_epochs500\"\n",
    "    path_predictions = \"../results/syn1/random/predictions.pkl\"\n",
    "    path_eval_set = \"../data/Eval-sets/eval-set-bashapes.pkl\"\n",
    "    path_data = \"../data/gnn_explainer/syn1.pickle\"\n",
    "\n",
    "elif DATASET == \"treecycles\":\n",
    "    path_log = \"../outputs/treecycles/1655241840/log.txt\"\n",
    "    path_cfs = \"../results/syn4/random/syn4_epochs500\"\n",
    "    path_predictions = \"../results/syn4/random/predictions.pkl\"\n",
    "    path_eval_set = \"../data/Eval-sets/eval-set-treecycles.pkl\"\n",
    "    path_data = \"../data/gnn_explainer/syn4.pickle\"\n",
    "\n",
    "elif DATASET == \"treegrids\":\n",
    "    path_log = \"../outputs/treegrids/1655242304/log.txt\"\n",
    "    path_cfs = \"../results/syn5/random/syn5_epochs500\"\n",
    "    path_predictions = \"../results/syn5/random/predictions.pkl\"\n",
    "    path_eval_set = \"../data/Eval-sets/eval-set-treegrids.pkl\"\n",
    "    path_data = \"../data/gnn_explainer/syn5.pickle\"\n",
    "\n",
    "else:\n",
    "    print(\"Invalid dataset!\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_data, \"rb\") as file:\n",
    "\tdata = pickle.load(file)\n",
    "\n",
    "adj = torch.Tensor(data[\"adj\"]).squeeze() # Does not include self loops\n",
    "features = torch.Tensor(data[\"feat\"]).squeeze()\n",
    "labels = torch.tensor(data[\"labels\"]).squeeze()\n",
    "idx_train = torch.tensor(data[\"train_idx\"])\n",
    "edge_index = dense_to_sparse(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_log, \"r\") as file:\n",
    "    log = file.readlines()\n",
    "\n",
    "with open(path_cfs, \"rb\") as file:\n",
    "    cfs = pickle.load(file)\n",
    "\n",
    "with open(path_predictions, \"rb\") as file:\n",
    "    predictions = pickle.load(file)\n",
    "\n",
    "with open(path_eval_set, \"rb\") as file:\n",
    "    eval_set = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Format of lists within cfs:\n",
    "\n",
    "If cf is not found for a node: []\n",
    "\n",
    "If cf is found for a node: [\n",
    "    0. 'node_idx', # index in the full graph\n",
    "    1. 'new_idx', # index in the extracted subgraph\n",
    "    2. 'cf_adj', # mask over the subgraph adjacency\n",
    "    3. 'sub_adj', # subgraph adjacency\n",
    "    4. 'pred_cf',\n",
    "    5. 'pred_orig',\n",
    "    6. 'sub_labels[new_idx]', # target node's predicted label in the subgraph\n",
    "    7. 'sub_adj.shape[0]', # #nodes in the subgraph\n",
    "    8. 'node_dict',\n",
    "    9. 'loss_graph_dist' # #edge-deletions\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == \"bashapes\":\n",
    "    NUMBER_OF_LABELS = 4\n",
    "else:\n",
    "    NUMBER_OF_LABELS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTIONS = {node:int(prediction) for node, prediction in enumerate(predictions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODES_PER_PREDICTED_LABEL = defaultdict(int)\n",
    "for node in PREDICTIONS:\n",
    "    label = PREDICTIONS[node]\n",
    "    NODES_PER_PREDICTED_LABEL[f\"label-{label}\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'label-1': 345, 'label-0': 526})\n"
     ]
    }
   ],
   "source": [
    "print(NODES_PER_PREDICTED_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTIONS_EVAL_SET = {node:label for node, label in PREDICTIONS.items() if node in eval_set}\n",
    "\n",
    "NODES_PER_PREDICTED_LABEL_IN_EVAL_SET = defaultdict(int)\n",
    "for node in PREDICTIONS_EVAL_SET:\n",
    "    label = PREDICTIONS_EVAL_SET[node]\n",
    "    NODES_PER_PREDICTED_LABEL_IN_EVAL_SET[f\"label-{label}\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'label-1': 72})\n"
     ]
    }
   ],
   "source": [
    "print(NODES_PER_PREDICTED_LABEL_IN_EVAL_SET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-label explanation size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a dictionary for each label\n",
    "per_label_explanation_size = defaultdict(list)\n",
    "nodes_per_prediction = defaultdict(int)\n",
    "\n",
    "# iterate over the cfs\n",
    "for cf in cfs:\n",
    "    # if cf wasn't found, skip to next iteration\n",
    "    if cf[4] == cf[5]:\n",
    "        continue\n",
    "    original_prediction = cf[5]\n",
    "    # just get cfs[-1][11] (which is the #edge-deletions)\n",
    "    perturbations = cf[9]\n",
    "    # store this against the corresponding label in the dictionry\n",
    "    per_label_explanation_size[f\"label-{int(original_prediction)}\"].append(int(perturbations))\n",
    "\n",
    "for label in per_label_explanation_size:\n",
    "    nodes_per_prediction[label] = len(per_label_explanation_size[label])\n",
    "\n",
    "for label in range(NUMBER_OF_LABELS):\n",
    "    # if there was no node in the eval-set with that label\n",
    "    if len(per_label_explanation_size[f\"label-{int(label)}\"]) == 0:\n",
    "        mean, std = None, None\n",
    "    else:\n",
    "        mean = np.mean(per_label_explanation_size[f\"label-{int(label)}\"])\n",
    "        std = np.std(per_label_explanation_size[f\"label-{int(label)}\"])\n",
    "    per_label_explanation_size[f\"label-{int(label)}\"] = [mean, std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-label Explanation size:\n",
      "label-1: 3.1805555555555554 +- 2.323350005253961\n",
      "label-0: None +- None\n",
      "\n",
      "Nodes per predicted label in the eval-set:\n",
      "defaultdict(<class 'int'>, {'label-1': 72})\n",
      "\n",
      "Nodes per post-perturbation-prediction in the eval-set:\n",
      "defaultdict(<class 'int'>, {'label-1': 72})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Per-label Explanation size:\")\n",
    "for key, value in per_label_explanation_size.items(): # format: label: (mean, std)\n",
    "    print(f\"{key}: {value[0]} +- {value[1]}\")\n",
    "print()\n",
    "print(f\"Nodes per predicted label in the eval-set:\\n{NODES_PER_PREDICTED_LABEL_IN_EVAL_SET}\\n\")\n",
    "print(f\"Nodes per post-perturbation-prediction in the eval-set:\\n{nodes_per_prediction}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_size = list()\n",
    "missed = 0\n",
    "# iterate over the cfs\n",
    "for cf in cfs:\n",
    "    # if cf wasn't found, hence skip\n",
    "    if cf[4] == cf[5]:\n",
    "        missed += 1\n",
    "        continue\n",
    "    explanation_size.append(int(cf[9]))\n",
    "# take mean and std\n",
    "explanation_size = [np.mean(explanation_size), np.std(explanation_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation_size:\n",
      "3.18 +- 2.32\n",
      "\n",
      "#Nodes in the eval set: 72\n",
      "#Nodes for which cf wasn't found: 0\n",
      "Hence, #nodes over which size was calculated: 72\n"
     ]
    }
   ],
   "source": [
    "print(\"Explanation_size:\")\n",
    "print(f\"{explanation_size[0]:.2f} +- {explanation_size[1]:.2f}\")\n",
    "print()\n",
    "print(f\"#Nodes in the eval set: {len(eval_set)}\")\n",
    "print(f\"#Nodes for which cf wasn't found: {missed}\")\n",
    "print(f\"Hence, #nodes over which size was calculated: {len(eval_set) - missed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-label Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_for_which_cf_was_found = [cf[0] for cf in cfs if cf[4] != cf[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_label_misses = defaultdict(int)\n",
    "\n",
    "# iterate over cfs\n",
    "for node in eval_set:\n",
    "    # get prediction\n",
    "    label = PREDICTIONS[node]\n",
    "    # check if cf was found\n",
    "    if node not in nodes_for_which_cf_was_found:\n",
    "        per_label_misses[f\"label-{label}\"] += 1\n",
    "\n",
    "per_label_fidelity = defaultdict(int)\n",
    "for label in per_label_misses:    \n",
    "    per_label_fidelity[label] = per_label_misses[label]/NODES_PER_PREDICTED_LABEL_IN_EVAL_SET[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {})\n"
     ]
    }
   ],
   "source": [
    "print(per_label_fidelity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity:\n",
      "0.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Fidelity:\")\n",
    "fidelity = 1 - len(nodes_for_which_cf_was_found)/len(eval_set)\n",
    "print(f\"{fidelity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_acc_list = list()\n",
    "# Iterate over the nodes in the eval set\n",
    "for cf in cfs:\n",
    "    if len(cf) == 0:\n",
    "        continue\n",
    "    target_node = cf[0]\n",
    "    cf_adj = cf[2]\n",
    "    sub_adj = cf[3]\n",
    "    # Extract the neighborhood.\n",
    "    data_sub_graph = get_neighbourhood(\n",
    "        node_idx=target_node,\n",
    "        edge_index=edge_index,\n",
    "        n_hops=4,\n",
    "        features=features,\n",
    "        labels=labels,\n",
    "    )\n",
    "    # Get the node mapping from sub_graph to full_graph.\n",
    "    __, __, __, node_dict = data_sub_graph\n",
    "    # Only possible because the values of the node_dict are all unique.\n",
    "    reverse_node_dict = {val:key for key, val in node_dict.items()}\n",
    "    # ! CFs are double counted here: (s,d), (d,s)\n",
    "    cf_sources, cf_destinations = (sub_adj - cf_adj).nonzero()\n",
    "    # Iterate over CFs\n",
    "    cf_acc = 0\n",
    "    for i in range(len(cf_sources)):\n",
    "        # get original indices of the mapped src and dest nodes.\n",
    "        src = reverse_node_dict[cf_sources[i]]\n",
    "        dest = reverse_node_dict[cf_destinations[i]]\n",
    "        # compute cf accuracy\n",
    "        if labels[src] != 0 and labels[dest] != 0:\n",
    "            cf_acc += 1\n",
    "    cf_acc = cf_acc / (len(cf_sources))\n",
    "    cf_acc_list.append(100 * cf_acc)\n",
    "cf_acc_mean = np.mean(cf_acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CF accuracy: 67.08 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"CF accuracy: {cf_acc_mean:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('gnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76f921cd2c7ba31dd50b19ee7b4bedccc75b7e402249f4fc3bf46d4878dd0fb9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
